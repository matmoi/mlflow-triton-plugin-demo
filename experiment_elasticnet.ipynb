{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine quality prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skl2onnx import to_onnx\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "MLFLOW_PORT = os.getenv(\"MLFLOW_PORT\", \"8080\")\n",
    "mlflow.set_tracking_uri(f\"http://localhost:{MLFLOW_PORT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skl2onnx import to_onnx\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "MLFLOW_PORT = os.getenv(\"MLFLOW_PORT\", \"8080\")\n",
    "TRITON_PORT_GRPC = os.getenv(\"TRITON_PORT_GRPC\", \"8001\")\n",
    "ONNX_MODEL_NAME = \"wine-quality-onnx\"\n",
    "\n",
    "mlflow.set_tracking_uri(f\"http://localhost:{MLFLOW_PORT}\")\n",
    "\n",
    "# Read the wine-quality csv file from the URL\n",
    "csv_url = (\n",
    "    \"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    ")\n",
    "try:\n",
    "    data = pd.read_csv(csv_url, sep=\";\")\n",
    "except Exception as e:\n",
    "    logger.exception(\n",
    "        \"Unable to download training & test CSV, check your internet connection. Error: %s\", e\n",
    "    )\n",
    "\n",
    "# Split the data into training and test sets. (0.75, 0.25) split.\n",
    "train, test = train_test_split(data)\n",
    "\n",
    "# The predicted column is \"quality\" which is a scalar from [3, 9]\n",
    "train_x = train.drop([\"quality\"], axis=1)\n",
    "test_x = test.drop([\"quality\"], axis=1)\n",
    "train_y = train[[\"quality\"]]\n",
    "test_y = test[[\"quality\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - training\n",
    "\n",
    "This tutorial is inspired from [here](https://www.mlflow.org/docs/1.20.2/tutorials-and-examples/tutorial.html). It showcases how you can use MLflow end-to-end to:\n",
    "- Train a linear regression model\n",
    "- Package the code that trains the model in a reusable and reproducible model format\n",
    "- Deploy the model\n",
    "\n",
    "This tutorial uses a dataset to predict the quality of wine based on quantitative features like the wine’s “fixed acidity”, “pH”, “residual sugar”, and so on.\n",
    "\n",
    "The data set used in this example is from http://archive.ics.uci.edu/ml/datasets/Wine+Quality\n",
    "P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis.\n",
    "Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "l1_ratio = 0.1\n",
    "\n",
    "def eval_metrics(actual, pred):\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(40)\n",
    "\n",
    "print(\"ready to start\")\n",
    "\n",
    "# Useful for multiple runs (only doing one run in this sample notebook)\n",
    "mlflow.set_experiment(\"wine-quality\")\n",
    "with mlflow.start_run():\n",
    "    print(\"starting run\")\n",
    "    # Execute ElasticNet\n",
    "    lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n",
    "    lr.fit(train_x, train_y)\n",
    "\n",
    "    # Evaluate Metrics\n",
    "    predicted_qualities = lr.predict(test_x)\n",
    "    (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n",
    "\n",
    "    # Print out metrics\n",
    "    print(f\"Elasticnet model (alpha={alpha:f}, l1_ratio={l1_ratio:f}):\")\n",
    "    print(\"  RMSE: %s\" % rmse)\n",
    "    print(\"  MAE: %s\" % mae)\n",
    "    print(\"  R2: %s\" % r2)\n",
    "\n",
    "    # Infer model signature\n",
    "    predictions = lr.predict(train_x)\n",
    "    signature = infer_signature(train_x, predictions)\n",
    "\n",
    "    # Log parameter, metrics, and model to MLflow\n",
    "    mlflow.log_param(\"alpha\", alpha)\n",
    "    mlflow.log_param(\"l1_ratio\", l1_ratio)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "\n",
    "    mlflow.sklearn.log_model(lr, \"wine-quality-sklearn\", signature=signature)\n",
    "\n",
    "    # convert to onnx\n",
    "    onx = to_onnx(lr, train_x[:1].to_numpy())\n",
    "    mlflow.onnx.log_model(onx, ONNX_MODEL_NAME, signature=signature, registered_model_name=ONNX_MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - run the model locally\n",
    "\n",
    "We use the mlflow tracking server to download and run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.onnx\n",
    "import onnxruntime as ort\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "# retrieve the most recent model version\n",
    "mlflow_client = MlflowClient()\n",
    "model_version = max(m.version for m in mlflow_client.search_model_versions(f\"name='{ONNX_MODEL_NAME}'\"))\n",
    "\n",
    "# load the model from mlflow\n",
    "model = mlflow.onnx.load_model(f\"models:/{ONNX_MODEL_NAME}/{model_version}\")\n",
    "\n",
    "# run the model with onnxruntime\n",
    "onnx_session = ort.InferenceSession(model.SerializeToString())\n",
    "input_name = onnx_session.get_inputs()[0].name\n",
    "test_results = onnx_session.run(None, {input_name: np.array(test_x[:4])})\n",
    "test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - update triton inference server with the new model\n",
    "\n",
    "Note that the same operation could be executed with the cmdline : \n",
    "\n",
    "```\n",
    "mlflow deployments create -t triton --flavor onnx --name wine-quality -m models:/wine-quality-onnx/<MODEL_VERSION>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow import MlflowClient\n",
    "from mlflow.deployments import get_deploy_client\n",
    "\n",
    "# retrieve the most recent model version\n",
    "mlflow_client = MlflowClient()\n",
    "model_version = max(m.version for m in mlflow_client.search_model_versions(f\"name='{ONNX_MODEL_NAME}'\"))\n",
    "\n",
    "client = get_deploy_client('triton')\n",
    "client.create_deployment(ONNX_MODEL_NAME, f\"models:/{ONNX_MODEL_NAME}/{model_version}\", flavor=\"onnx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - run inference from the model deployed in the triton inference server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tritonclient.grpc as grpcclient\n",
    "triton_client = grpcclient.InferenceServerClient(\n",
    "    url=f\"localhost:{TRITON_PORT_GRPC}\", verbose=True\n",
    ")\n",
    "input = grpcclient.InferInput(\"X\", [4,11], \"FP64\")\n",
    "input.set_data_from_numpy(np.atleast_2d(test_x.iloc[:4].to_numpy()))\n",
    "result = triton_client.infer(ONNX_MODEL_NAME, inputs=[input])\n",
    "result.as_numpy(\"variable\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
